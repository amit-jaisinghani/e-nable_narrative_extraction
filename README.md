# eNable_narrative_extraction

Data analysis for e-nable

Preprocessing.py loads the labelled data in Pandas data frame. <br>
Sequence_Classification.py uses this load data to train model and test its accuracy.

How to run the code: <br>
Preprocessing.py contains path to the labelled data. <br>
This path needs to be updated and run Sequence_Classification.py to execute program.

Steps:
1. Update csvpath with training data path in Preprocessing.py. Example: csvpath = "./data/train.csv" <br>
2. Run Sequence_Classification.py. Example: python3 Sequence_Classification.py

Sample Ouput:
Train on 494 samples, validate on 124 samples
Epoch 1/1

 10/494 [..............................] - ETA: 54s - loss: 3.5091 - acc: 0.7000 <br>
 20/494 [>.............................] - ETA: 37s - loss: 3.6013 - acc: 0.6500 <br>
 30/494 [>.............................] - ETA: 31s - loss: 3.4198 - acc: 0.6333 <br>
 40/494 [=>............................] - ETA: 28s - loss: 3.3807 - acc: 0.6250 <br>
 50/494 [==>...........................] - ETA: 26s - loss: 3.3076 - acc: 0.6200 <br>
 60/494 [==>...........................] - ETA: 24s - loss: 3.4578 - acc: 0.6500 <br>
 70/494 [===>..........................] - ETA: 23s - loss: 3.3926 - acc: 0.6429 <br>
 80/494 [===>..........................] - ETA: 22s - loss: 3.4467 - acc: 0.6375 <br>
 90/494 [====>.........................] - ETA: 21s - loss: 3.4574 - acc: 0.6556 <br>
100/494 [=====>........................] - ETA: 20s - loss: 3.4257 - acc: 0.6300 <br>
110/494 [=====>........................] - ETA: 20s - loss: 3.4073 - acc: 0.6364 <br>
120/494 [======>.......................] - ETA: 20s - loss: 3.3010 - acc: 0.6083 <br>
130/494 [======>.......................] - ETA: 19s - loss: 3.2786 - acc: 0.5923 <br>
140/494 [=======>......................] - ETA: 18s - loss: 3.2605 - acc: 0.6071 <br>
150/494 [========>.....................] - ETA: 17s - loss: 3.2449 - acc: 0.6000 <br>
160/494 [========>.....................] - ETA: 17s - loss: 3.2140 - acc: 0.6000 <br>
170/494 [=========>....................] - ETA: 16s - loss: 3.1980 - acc: 0.5824 <br>
180/494 [=========>....................] - ETA: 16s - loss: 3.1908 - acc: 0.5944 <br>
190/494 [==========>...................] - ETA: 15s - loss: 3.1351 - acc: 0.5842 <br>
200/494 [===========>..................] - ETA: 15s - loss: 3.0889 - acc: 0.5750 <br>
210/494 [===========>..................] - ETA: 14s - loss: 3.0529 - acc: 0.5714 <br>
220/494 [============>.................] - ETA: 14s - loss: 3.0731 - acc: 0.5682 <br>
230/494 [============>.................] - ETA: 13s - loss: 3.0620 - acc: 0.5652 <br>
240/494 [=============>................] - ETA: 13s - loss: 3.0121 - acc: 0.5667 <br>
250/494 [==============>...............] - ETA: 12s - loss: 3.0256 - acc: 0.5640 <br>
260/494 [==============>...............] - ETA: 12s - loss: 3.0260 - acc: 0.5654 <br>
270/494 [===============>..............] - ETA: 11s - loss: 3.0107 - acc: 0.5556 <br>
280/494 [================>.............] - ETA: 10s - loss: 3.0034 - acc: 0.5500 <br>
290/494 [================>.............] - ETA: 10s - loss: 2.9580 - acc: 0.5517 <br>
300/494 [=================>............] - ETA: 9s - loss: 2.9651 - acc: 0.5567  <br>
310/494 [=================>............] - ETA: 9s - loss: 2.9310 - acc: 0.5613 <br>
320/494 [==================>...........] - ETA: 8s - loss: 2.9244 - acc: 0.5594 <br>
330/494 [===================>..........] - ETA: 8s - loss: 2.9025 - acc: 0.5545 <br>
340/494 [===================>..........] - ETA: 7s - loss: 2.8939 - acc: 0.5559 <br>
350/494 [====================>.........] - ETA: 7s - loss: 2.8639 - acc: 0.5543 <br>
360/494 [====================>.........] - ETA: 6s - loss: 2.8444 - acc: 0.5583 <br>
370/494 [=====================>........] - ETA: 6s - loss: 2.8465 - acc: 0.5568 <br>
380/494 [======================>.......] - ETA: 5s - loss: 2.8269 - acc: 0.5579 <br>
390/494 [======================>.......] - ETA: 5s - loss: 2.8360 - acc: 0.5590 <br>
400/494 [=======================>......] - ETA: 4s - loss: 2.8303 - acc: 0.5525 <br>
410/494 [=======================>......] - ETA: 4s - loss: 2.8288 - acc: 0.5561 <br>
420/494 [========================>.....] - ETA: 3s - loss: 2.8298 - acc: 0.5524 <br>
430/494 [=========================>....] - ETA: 3s - loss: 2.8273 - acc: 0.5512 <br>
440/494 [=========================>....] - ETA: 2s - loss: 2.8324 - acc: 0.5500 <br>
450/494 [==========================>...] - ETA: 2s - loss: 2.8299 - acc: 0.5489 <br>
460/494 [==========================>...] - ETA: 1s - loss: 2.8168 - acc: 0.5500 <br>
470/494 [===========================>..] - ETA: 1s - loss: 2.7986 - acc: 0.5468 <br>
480/494 [============================>.] - ETA: 0s - loss: 2.8013 - acc: 0.5417 <br>
490/494 [============================>.] - ETA: 0s - loss: 2.7819 - acc: 0.5367 <br>
494/494 [==============================] - 26s 53ms/step - loss: 2.7804 - acc: 0.5344 - val_loss: 2.3859 - val_acc: 0.7500 <br>

Note: 
Sequence_Classification.py splits training set into 80-20 where 80% is used for training and 20% for validation
